{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2_evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOqU3S9WyQ0ETlphlLN6RZ1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Start by installing required libraries (mainly Transformers)\n",
        "!pip install transformers==4.17.0\n",
        "!pip install scikit-learn\n",
        "!pip install hydra-core\n",
        "!pip install pronouncing\n",
        "!pip install spacy"
      ],
      "metadata": {
        "id": "Wm3SvXWmNAHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only needed when running in colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\", force_remount=True)"
      ],
      "metadata": {
        "id": "HaPU47duNC7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/coderalo/11785-automatic-poetry-generation.git"
      ],
      "metadata": {
        "id": "Ayf4KLuLRXUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import glob\n",
        "import json\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pronouncing\n",
        "import random\n",
        "import shutil\n",
        "import string as string_utils\n",
        "import sys\n",
        "import tempfile\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import tqdm.notebook as tqdm\n",
        "import yaml\n",
        "\n",
        "from hydra import compose\n",
        "from hydra import initialize_config_dir\n",
        "from omegaconf import OmegaConf\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import GPT2LMHeadModel\n",
        "from transformers import GPT2Model\n",
        "from transformers import GPT2Tokenizer"
      ],
      "metadata": {
        "id": "D-X1WieqOU1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rhyming distance calculation"
      ],
      "metadata": {
        "id": "pHC2kjw4GqoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "tokenizer = nlp.tokenizer"
      ],
      "metadata": {
        "id": "cjB60O7GocVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_rhyme(limerick):\n",
        "    assert len(limerick) == 5\n",
        "    for idx, line in enumerate(limerick):\n",
        "        while len(line) >= 1 and line[-1] in string_utils.punctuation:\n",
        "            line = line[:-1]\n",
        "        limerick[idx] = line\n",
        "\n",
        "    for line in limerick:\n",
        "        if line == \"\":\n",
        "            return None\n",
        "\n",
        "    words = []\n",
        "    for line in limerick:\n",
        "        words.append(tokenizer(line)[-1].text)\n",
        "\n",
        "    pairs = [[0, 1], [2, 3], [0, 4], [1, 4]]\n",
        "    distance = 0.\n",
        "    for pair in pairs:\n",
        "        word_0, word_1 = words[pair[0]], words[pair[1]]\n",
        "        phones_0 = pronouncing.phones_for_word(word_0)\n",
        "        if phones_0 == []:\n",
        "            return None\n",
        "        phones_0 = pronouncing.rhyming_part(phones_0[0])\n",
        "        phones_1 = pronouncing.phones_for_word(word_1)\n",
        "        if phones_1 == []:\n",
        "            return None\n",
        "        phones_1 = pronouncing.rhyming_part(phones_1[0])\n",
        "        if phones_0 != phones_1:\n",
        "            distance += 1 / len(pairs)\n",
        "\n",
        "    # if flag is False:\n",
        "    #     print(limerick)\n",
        "      \n",
        "    return distance"
      ],
      "metadata": {
        "id": "U6qFrTSZqN_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vocabulary coverage calculation"
      ],
      "metadata": {
        "id": "UFXanVFgGven"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "9huRee4F7TKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = json.load(open(\"/content/drive/MyDrive/11-785-final/data/limericks.json\", 'r'))\n",
        "oedilf_word_freq = Counter()\n",
        "for key, value in data[\"limericks\"].items():\n",
        "    lines = value[\"lines\"]\n",
        "    for line in lines:\n",
        "        words = [token.text for token in tokenizer(line)]\n",
        "        oedilf_word_freq.update(words)\n",
        "\n",
        "for punct in string_utils.punctuation:\n",
        "    if punct in oedilf_word_freq:\n",
        "        oedilf_word_freq.pop(punct)"
      ],
      "metadata": {
        "id": "K2mmp6aQ6ks3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_freq(files):\n",
        "    generated_word_freq = Counter()\n",
        "\n",
        "    for filename in files:\n",
        "        with open(filename, 'r') as file:\n",
        "            for _ in range(100):\n",
        "                limerick = []\n",
        "                for _ in range(5):\n",
        "                    limerick.append(file.readline().strip())\n",
        "                file.readline()\n",
        "                for line in limerick:\n",
        "\n",
        "                    words = [token.text for token in tokenizer(line)]\n",
        "                    generated_word_freq.update(words)\n",
        "\n",
        "    for punct in string_utils.punctuation:\n",
        "        if punct in generated_word_freq:\n",
        "            generated_word_freq.pop(punct)\n",
        "\n",
        "    return generated_word_freq"
      ],
      "metadata": {
        "id": "e6HYpHs3G5GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_coverage(oedilf_word_freq, generated_word_freq, min_word_freq):\n",
        "    top_words = set()\n",
        "    for word, count in oedilf_word_freq.most_common():\n",
        "        if count < min_word_freq:\n",
        "            break\n",
        "        top_words.add(word)\n",
        "\n",
        "    covered, total = 0, 0\n",
        "    for word, count in generated_word_freq.most_common():\n",
        "        if word in top_words:\n",
        "            covered += count\n",
        "        total += count    \n",
        "\n",
        "    coverage = covered / total\n",
        "    return coverage"
      ],
      "metadata": {
        "id": "wcqk5S2aHGNn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}